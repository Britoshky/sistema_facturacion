"""
CloudMusic DTE AI - Response Quality Validator
Validador de calidad para respuestas de IA

Funcionalidades:
- AnÃ¡lisis de calidad pre-envÃ­o
- DetecciÃ³n de contenido genÃ©rico
- Scoring automÃ¡tico de respuestas
- ActivaciÃ³n de re-generaciÃ³n inteligente
"""

import logging
import re
from typing import Dict, Any, Tuple, List
from dataclasses import dataclass
from enum import Enum

class QualityLevel(Enum):
    EXCELLENT = "excellent"  # 85-100
    GOOD = "good"           # 70-84
    AVERAGE = "average"     # 55-69
    POOR = "poor"          # 40-54
    UNACCEPTABLE = "unacceptable"  # 0-39

@dataclass
class QualityMetrics:
    """MÃ©tricas de calidad de respuesta"""
    specificity_score: float = 0.0
    personalization_score: float = 0.0
    completeness_score: float = 0.0
    accuracy_score: float = 0.0
    engagement_score: float = 0.0
    total_score: float = 0.0
    quality_level: QualityLevel = QualityLevel.UNACCEPTABLE
    improvement_suggestions: List[str] = None
    generic_patterns_found: List[str] = None

class ResponseQualityValidator:
    """Validador de calidad de respuestas de IA"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Patrones genÃ©ricos que reducen calidad (penalizaciones)
        self.generic_patterns = {
            r'\bel administrador\b': -15,  # Muy genÃ©rico
            r'admin@empresa\.cl': -20,     # Email genÃ©rico
            r'\bSu empresa\b': -10,        # Referencia genÃ©rica
            r'\bla empresa\b': -8,         # Referencia genÃ©rica
            r'InformaciÃ³n empresarial completa:\s*ðŸ‘¤\s*\*\*Administrador:\*\*\s*el administrador': -25,
            r'Me alegra\s*(poder\s*)?ayudar': -5,  # IntroducciÃ³n genÃ©rica
            r'Â¡Hola!': -5,                # Saludo genÃ©rico
            r'Soy CloudMusic IA': -8,     # AutoidentificaciÃ³n genÃ©rica
            r'estimado\s*(cliente|usuario)': -3,  # Tratamiento genÃ©rico
        }
        
        # Patrones especÃ­ficos que aumentan calidad (bonificaciones)
        self.specific_patterns = {
            r'\bCloudMusic SpA\b': +10,           # Empresa especÃ­fica
            r'\bCarlos Administrador\b': +15,     # Nombre especÃ­fico
            r'admin@cloudmusic\.cl': +15,         # Email especÃ­fico
            r'78218659-0': +10,                   # RUT especÃ­fico
            r'\$\d{1,3}(?:\.\d{3})*': +5,       # Montos especÃ­ficos
            r'\b\d{1,2}/\d{1,2}/\d{4}\b': +5,   # Fechas especÃ­ficas
            r'cÃ³digo\s*\d+': +8,                # CÃ³digos DTE especÃ­ficos
            r'factura\s*electrÃ³nica': +5,        # TerminologÃ­a DTE
            r'boleta\s*electrÃ³nica': +5,         # TerminologÃ­a DTE
        }
        
        # Criterios de completitud
        self.completeness_indicators = [
            r'âœ…',  # Checks de confirmaciÃ³n
            r'ðŸ“‹',  # InformaciÃ³n estructurada
            r'ðŸ‘¤',  # Datos personales
            r'ðŸ“§',  # Contacto
            r'ðŸ¢',  # Empresa
            r'ðŸ’°',  # InformaciÃ³n financiera
        ]
        
        self.logger.info("ðŸ” ResponseQualityValidator inicializado")
    
    async def validate_response(
        self, 
        response_text: str, 
        user_query: str,
        context_data: Dict[str, Any] = None
    ) -> QualityMetrics:
        """
        Valida calidad de respuesta generada
        
        Args:
            response_text: Texto de la respuesta
            user_query: Consulta original del usuario
            context_data: Datos de contexto disponibles
            
        Returns:
            QualityMetrics con scoring detallado
        """
        try:
            metrics = QualityMetrics(improvement_suggestions=[], generic_patterns_found=[])
            
            # 1. AnÃ¡lisis de especificidad
            metrics.specificity_score = await self._analyze_specificity(response_text, metrics)
            
            # 2. AnÃ¡lisis de personalizaciÃ³n  
            metrics.personalization_score = await self._analyze_personalization(
                response_text, context_data, metrics
            )
            
            # 3. AnÃ¡lisis de completitud
            metrics.completeness_score = await self._analyze_completeness(
                response_text, user_query, metrics
            )
            
            # 4. AnÃ¡lisis de precisiÃ³n
            metrics.accuracy_score = await self._analyze_accuracy(response_text, metrics)
            
            # 5. AnÃ¡lisis de engagement
            metrics.engagement_score = await self._analyze_engagement(response_text, metrics)
            
            # CÃ¡lculo de score total (ponderado)
            metrics.total_score = (
                metrics.specificity_score * 0.25 +      # 25%
                metrics.personalization_score * 0.25 +  # 25%
                metrics.completeness_score * 0.20 +     # 20%
                metrics.accuracy_score * 0.20 +         # 20%
                metrics.engagement_score * 0.10         # 10%
            )
            
            # Determinar nivel de calidad
            metrics.quality_level = self._determine_quality_level(metrics.total_score)
            
            self.logger.info(f"ðŸ” Respuesta evaluada: {metrics.total_score:.1f}/100 ({metrics.quality_level.value})")
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"âŒ Error en validaciÃ³n de respuesta: {e}")
            return QualityMetrics()
    
    async def _analyze_specificity(self, text: str, metrics: QualityMetrics) -> float:
        """Analiza especificidad vs contenido genÃ©rico"""
        
        try:
            base_score = 50.0  # Score base
            
            # Penalizar patrones genÃ©ricos
            for pattern, penalty in self.generic_patterns.items():
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    base_score += penalty * len(matches)
                    metrics.generic_patterns_found.extend([f"GenÃ©rico: {match}" for match in matches])
            
            # Bonificar patrones especÃ­ficos
            for pattern, bonus in self.specific_patterns.items():
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    base_score += bonus * len(matches)
            
            # Normalizar entre 0-100
            return max(0, min(100, base_score))
            
        except Exception as e:
            self.logger.error(f"âŒ Error analizando especificidad: {e}")
            return 0.0
    
    async def _analyze_personalization(
        self, 
        text: str, 
        context_data: Dict[str, Any], 
        metrics: QualityMetrics
    ) -> float:
        """Analiza nivel de personalizaciÃ³n"""
        
        try:
            score = 0.0
            
            if not context_data:
                metrics.improvement_suggestions.append("Usar mÃ¡s datos de contexto empresarial")
                return 30.0  # Score bÃ¡sico sin contexto
            
            # Verificar uso de datos personales
            if context_data.get('admin_name') and context_data['admin_name'] in text:
                score += 25
            else:
                metrics.improvement_suggestions.append("Incluir nombre del administrador especÃ­fico")
            
            if context_data.get('company_name') and context_data['company_name'] in text:
                score += 25
            else:
                metrics.improvement_suggestions.append("Mencionar nombre de empresa especÃ­fico")
                
            if context_data.get('admin_email') and context_data['admin_email'] in text:
                score += 20
            else:
                metrics.improvement_suggestions.append("Incluir email especÃ­fico de contacto")
                
            # Verificar contextualizaciÃ³n empresarial
            if any(indicator in text for indicator in ['DTE', 'factura', 'boleta', 'SII']):
                score += 15
                
            # Verificar datos financieros especÃ­ficos
            if re.search(r'\$[\d\.,]+', text):
                score += 15
            
            return min(100, score)
            
        except Exception as e:
            self.logger.error(f"âŒ Error analizando personalizaciÃ³n: {e}")
            return 0.0
    
    async def _analyze_completeness(self, text: str, query: str, metrics: QualityMetrics) -> float:
        """Analiza completitud de la respuesta"""
        
        try:
            score = 20.0  # Score base
            
            # Verificar presencia de elementos estructurados
            for indicator in self.completeness_indicators:
                if indicator in text:
                    score += 10
            
            # Verificar longitud apropiada (no muy corta ni muy larga)
            text_length = len(text.strip())
            if 100 <= text_length <= 800:
                score += 20
            elif text_length < 50:
                score -= 20
                metrics.improvement_suggestions.append("Respuesta muy breve, agregar mÃ¡s detalles")
            elif text_length > 1200:
                score -= 10
                metrics.improvement_suggestions.append("Respuesta muy extensa, ser mÃ¡s conciso")
            
            # Verificar que responda a la consulta
            query_words = set(query.lower().split())
            text_words = set(text.lower().split())
            relevance = len(query_words.intersection(text_words)) / len(query_words)
            score += relevance * 30
            
            return min(100, score)
            
        except Exception as e:
            self.logger.error(f"âŒ Error analizando completitud: {e}")
            return 0.0
    
    async def _analyze_accuracy(self, text: str, metrics: QualityMetrics) -> float:
        """Analiza precisiÃ³n y veracidad"""
        
        try:
            score = 70.0  # Score base (asumiendo precisiÃ³n)
            
            # Verificar inconsistencias obvias
            inconsistency_patterns = [
                (r'admin@empresa\.cl.*admin@cloudmusic\.cl', -15),  # Emails contradictorios
                (r'el administrador.*Carlos Administrador', -10),   # Nombres contradictorios
                (r'Su empresa.*CloudMusic SpA', -5),               # Referencias contradictorias
            ]
            
            for pattern, penalty in inconsistency_patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    score += penalty
                    metrics.improvement_suggestions.append("Resolver inconsistencias en la informaciÃ³n")
            
            # Bonificar informaciÃ³n tÃ©cnica correcta
            technical_patterns = [
                r'cÃ³digo\s*33',      # Factura electrÃ³nica
                r'cÃ³digo\s*39',      # Boleta electrÃ³nica  
                r'cÃ³digo\s*61',      # Nota de crÃ©dito
                r'RUT\s*\d{8}-[\dKk]',  # Formato RUT vÃ¡lido
            ]
            
            for pattern in technical_patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    score += 5
            
            return min(100, max(0, score))
            
        except Exception as e:
            self.logger.error(f"âŒ Error analizando precisiÃ³n: {e}")
            return 70.0
    
    async def _analyze_engagement(self, text: str, metrics: QualityMetrics) -> float:
        """Analiza nivel de engagement y conversacionalidad"""
        
        try:
            score = 50.0  # Score base
            
            # Bonificar elementos que mejoran engagement
            engagement_elements = [
                (r'âœ…', +8),   # Confirmaciones visuales
                (r'ðŸ“‹', +5),   # InformaciÃ³n estructurada
                (r'ðŸ’¡', +5),   # Tips o sugerencias
                (r'âš¡', +3),   # Elementos dinÃ¡micos
                (r'ðŸ”', +3),   # Elementos exploratorios
            ]
            
            for pattern, bonus in engagement_elements:
                matches = len(re.findall(pattern, text))
                score += bonus * min(matches, 3)  # MÃ¡ximo 3 bonificaciones por elemento
            
            # Penalizar respuestas muy robÃ³ticas
            if not re.search(r'[.!?]', text):
                score -= 10
                metrics.improvement_suggestions.append("AÃ±adir puntuaciÃ³n para mejor legibilidad")
            
            # Bonificar estructura clara
            if re.search(r'\*\*.*\*\*', text):  # Headers en markdown
                score += 10
            
            return min(100, max(0, score))
            
        except Exception as e:
            self.logger.error(f"âŒ Error analizando engagement: {e}")
            return 50.0
    
    def _determine_quality_level(self, score: float) -> QualityLevel:
        """Determina nivel de calidad basado en score"""
        
        if score >= 85:
            return QualityLevel.EXCELLENT
        elif score >= 70:
            return QualityLevel.GOOD
        elif score >= 55:
            return QualityLevel.AVERAGE
        elif score >= 40:
            return QualityLevel.POOR
        else:
            return QualityLevel.UNACCEPTABLE
    
    async def should_regenerate_response(self, metrics: QualityMetrics, threshold: float = 75.0) -> bool:
        """
        Determina si la respuesta debe regenerarse
        
        Args:
            metrics: MÃ©tricas de calidad
            threshold: Umbral mÃ­nimo de calidad
            
        Returns:
            True si debe regenerarse
        """
        return (
            metrics.total_score < threshold or
            metrics.quality_level in [QualityLevel.POOR, QualityLevel.UNACCEPTABLE] or
            len(metrics.generic_patterns_found) > 2
        )
    
    def generate_improvement_report(self, metrics: QualityMetrics) -> str:
        """Genera reporte de mejoras sugeridas"""
        
        report = f"""
ðŸ“Š **Reporte de Calidad de Respuesta**

ðŸŽ¯ **Score Total:** {metrics.total_score:.1f}/100 ({metrics.quality_level.value})

ðŸ“ˆ **Scores Detallados:**
â€¢ Especificidad: {metrics.specificity_score:.1f}/100
â€¢ PersonalizaciÃ³n: {metrics.personalization_score:.1f}/100  
â€¢ Completitud: {metrics.completeness_score:.1f}/100
â€¢ PrecisiÃ³n: {metrics.accuracy_score:.1f}/100
â€¢ Engagement: {metrics.engagement_score:.1f}/100

ðŸš¨ **Patrones GenÃ©ricos Detectados:** {len(metrics.generic_patterns_found)}
{chr(10).join(f"  â€¢ {pattern}" for pattern in metrics.generic_patterns_found[:5])}

ðŸ’¡ **Sugerencias de Mejora:**
{chr(10).join(f"  â€¢ {suggestion}" for suggestion in metrics.improvement_suggestions[:5])}
        """
        
        return report.strip()